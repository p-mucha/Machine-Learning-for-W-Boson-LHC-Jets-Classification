{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This code is part of the code I wrote as my submission for the mini project from PHAS0056 Practical Machine Learning.\n",
    "\n",
    "# Introduction\n",
    "\n",
    "In this notebook, Convolutional Neural Network is developed to classify LHC jets from W bosons and QCD, using imaging technique. Images display transverse energy of the jet deposited in detectors. Jets from W bosons are considered signal and those from QCD - background.\n",
    "Data taken from: https://www.hep.ucl.ac.uk/undergrad/0056/other/projects/jetimage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: /device:CPU:0\n",
      "Device type: CPU\n",
      "Memory limit: 268435456\n"
     ]
    }
   ],
   "source": [
    "local_devices = device_lib.list_local_devices()\n",
    "\n",
    "for device in local_devices:\n",
    "    print(f\"Device name: {device.name}\")\n",
    "    print(f\"Device type: {device.device_type}\")\n",
    "    print(f\"Memory limit: {device.memory_limit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(94) # setting random seed value for reproducibility\n",
    "\n",
    "# Variables for network compiling:\n",
    "#loss function\n",
    "loss_function = 'categorical_crossentropy' #'mean_squared_logarithmic_error' #'mean_squared_error' #'categorical_crossentropy'\n",
    "\n",
    "vector_length = 40 *40 # Image size\n",
    "\n",
    "optimizer = 'adam' # optimizer\n",
    "nb_epochs = 10 # number of epochs for training\n",
    "multi_gpu_training = False\n",
    "\n",
    "nb_top_lund_planes = 10000 # Number of top quark jet images to be loaded\n",
    "nb_QCD_lund_planes = 10000 # Number of qcd jet images to be loaded\n",
    "nb_W_lund_planes = 10000 # Number of W boson jet images to be loaded\n",
    "model_name = 'CNN'\n",
    "\n",
    "do_shuffle = True\n",
    "save_trained_model = False\n",
    "test_sample_size = 0.25 # fraction of dataset that will be used for training, in this case 25%, so 5000 of 20 000 images\n",
    "\n",
    "# Input filename, we begin with 600 - 1500 range of transverse momentum\n",
    "input_filename = \"20190920_pt600.0_1500.0_40bins_10k.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loading {} feature vector dataset...\".format(vector_length))\n",
    "\n",
    "# import data from the file\n",
    "input_data = np.load(input_filename)\n",
    "top_samples = input_data['top_jet_images'][:nb_top_lund_planes]\n",
    "w_samples = input_data['W_jet_images'][:nb_W_lund_planes]\n",
    "qcd_samples = input_data['QCD_jet_images'][:nb_QCD_lund_planes]\n",
    "\n",
    "\n",
    "# renaming\n",
    "X_BG = qcd_samples # background\n",
    "# X_S = top_samples # top quark jets - signal\n",
    "X_S = w_samples # W boson jets - signal\n",
    "\n",
    "\n",
    "print(\"S samples:\", len(X_S))\n",
    "print(\"BG samples:\", len(X_BG))\n",
    "print(\"ratio S/BG:\", len(X_S) / len(X_BG))\n",
    "\n",
    "\n",
    "#np.random.shuffle(X_BG)\n",
    "\n",
    "#Label data\n",
    "y_S = np.ones(len(X_S)) # signal label \"1\"\n",
    "y_BG = np.zeros(len(X_BG)) # background label \"0\"\n",
    "\n",
    "# combine images with their labels in arrays\n",
    "X = np.append(X_S, X_BG, axis=0) \n",
    "y = np.append(y_S, y_BG, axis=0)\n",
    "\n",
    "\n",
    "# CNN architecture is built to take color images. \n",
    "# Therefore, input shape is: 1 colour channel + 1 imagege channel (flattened)\n",
    "X = X.reshape( (X.shape[0], X.shape[1], X.shape[2], 1) )\n",
    "\n",
    "# Split data into training and testing samples while shuffling for random order\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_sample_size, shuffle=do_shuffle)\n",
    "\n",
    "\n",
    "# Reshape target vectors\n",
    "y = to_categorical(y, 2)\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_test = to_categorical(y_test, 2)\n",
    "\n",
    "input_shape = X[0].shape # signle image shape\n",
    "print(\"Input vector shape:\", input_shape)\n",
    "print(\"Number of input samples:\", len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train has shape: \", X_train.shape , \"y_train has shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 15000 images used for training, each of size 40 by 40 with one channel. Respectively, there are 15000 labels for the images, each of shape 2, [0,1] for signal and [1,0] for background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random number for plotting randomly chosen of images\n",
    "iimg_sig = np.random.randint(0, len(X_S))\n",
    "iimg_bkg = np.random.randint(0, len(X_BG)) \n",
    "\n",
    "# start figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# plot the image\n",
    "im = ax.imshow(X_S[iimg_sig].reshape(X_S.shape[1], X_S.shape[2]), origin=\"lower\")\n",
    "ax.set_title(\"Example of a signal jet image\")\n",
    "\n",
    "# colorbar with label\n",
    "cbar = fig.colorbar(im)\n",
    "cbar.ax.set_ylabel('Transverse Energy')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# start figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# plot the image\n",
    "im = ax.imshow(X_BG[iimg_bkg].reshape(X_BG.shape[1], X_BG.shape[2]), origin=\"lower\")\n",
    "ax.set_title(\"Example of a background jet image\")\n",
    "\n",
    "# colorbar with label\n",
    "cbar = fig.colorbar(im)\n",
    "cbar.ax.set_ylabel('Transverse Energy')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# start figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# plot the image\n",
    "im = ax.imshow(np.sum(X_S, axis=0).reshape(X_S.shape[1], X_S.shape[2]), origin=\"lower\")\n",
    "ax.set_title(\"Sum of signal jet images\")\n",
    "\n",
    "# colorbar with label\n",
    "cbar = fig.colorbar(im)\n",
    "cbar.ax.set_ylabel('Transverse Energy')\n",
    "\n",
    "#fig.savefig('jet_image.png', dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# start figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# plot the image\n",
    "im = ax.imshow(np.sum(X_BG, axis=0).reshape(X_BG.shape[1], X_BG.shape[2]), origin=\"lower\")\n",
    "ax.set_title(\"Sum of background jet images\")\n",
    "\n",
    "# colorbar with label\n",
    "cbar = fig.colorbar(im)\n",
    "cbar.ax.set_ylabel('Transverse Energy')\n",
    "\n",
    "#fig.savefig('jet_image.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# first convolutional layer, with 32 filters of size 3x3, input shape (40,40,1)\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(40, 40, 1)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2))) # maxpooling 2x2\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu')) # second convolutional layer with 64 filters\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2))) # maxpooling 2x2\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu')) # third convolutional layer, 64 filters\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2))) # maxpooling 2x2\n",
    "\n",
    "# dropout layer for reducing overfitting\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "# begin dense layers, for that flatten input from convolutional layers\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "# dense layers\n",
    "model.add(keras.layers.Dense(256, activation='relu')) # dense layer, 256 nodes\n",
    "model.add(keras.layers.Dense(128, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(48, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(2, activation='softmax')) # final layer with two outputs for binary classification\n",
    "\n",
    "# compile model\n",
    "model.compile(loss=loss_function, \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.0004),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model.summary()\n",
    "\n",
    "# train model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=10, \n",
    "                    batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the network's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy and validation accuracy vs epoch number\n",
    "plt.plot(history.history['accuracy'], '.-', label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], '.-', label = 'validation accuracy')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "#plt.ylim([0.6, 0.85])\n",
    "plt.grid()\n",
    "plt.title('Accuracy of the model versus epoch number')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final accuracy is slightly above 0.79. It is difficult to tell without any context whether this value is high or low for this specific problem. This is investigated more below. The learning is stopped at 10 epochs, as this is roughly when network stops improving and overfitting starts. As can be seen on the graph, validation accuracy and accuracy are correlated, and the overfitiing at the end is very small. This indicates a good model. Learning rate and number of epochs in the model have been chosen in such a way to minimize overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot loss functions across the epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss and validation loss vs epoch number\n",
    "plt.plot(history.history['loss'], '.-', label='loss')\n",
    "plt.plot(history.history['val_loss'], '.-', label = 'validation loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss function')\n",
    "plt.grid()\n",
    "plt.title('Loss function of the model vs epoch number')\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can take a look at those of the images that are misidentified by the model, to see if there are any patterns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0 # index for the loop\n",
    "misidentified_BG = [] # background misidentified as signal list\n",
    "misidentified_S = [] # signal misidentified as background\n",
    "\n",
    "# loop over all test images\n",
    "while index < X_test.shape[0]:\n",
    "    input_image = X_test[index]\n",
    "\n",
    "    input_image = input_image.reshape( 1,40,40,1) # reshape for the prediction\n",
    "\n",
    "    prediction = model.predict(input_image) # model predict\n",
    "\n",
    "    # since prediction is in form [a,b], where a and b are confidence levels that it is background (a) and signal (b)\n",
    "    # we can take index number of the greater of those values. E.g if a is greater, then network predicts background\n",
    "    predicted_class = np.argmax(prediction)\n",
    "\n",
    "\n",
    "    if prediction[0][0] > prediction[0][1]: # this is predicted as 0\n",
    "        if y_test[index][1] > y_test[index][0]:\n",
    "            print(\"wrong, this is 1 (signal)\")\n",
    "            # predicted as background but it is really signal\n",
    "            misidentified_S.append(X_test[index]) # update list\n",
    "\n",
    "\n",
    "    elif y_test[index][0] > y_test[index][1]: \n",
    "        print(\"wrong, this is 0 (background)\")\n",
    "        # predicted as signal, but it is really background\n",
    "        misidentified_BG.append(X_test[index]) # update list\n",
    "        \n",
    "        \n",
    "    index = index + 1 # index increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn lists into arrays\n",
    "misidentified_BG = np.array(misidentified_BG)\n",
    "misidentified_S = np.array(misidentified_S)\n",
    "\n",
    "print(\"There are \",misidentified_BG.shape[0], \"BG misidentified as S\")\n",
    "print(\"There are\",misidentified_S.shape[0], \"S misidentified as BG\")\n",
    "print(\"Total accuracy, on all test images is: \", 1 - (misidentified_BG.shape[0] + misidentified_S.shape[0])/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is noticeable that network more often misidentifies signals than backgrounds. This might be a good result, as in some cases it might be better to have less false positives at cost of less true positives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# plot the image\n",
    "im = ax.imshow(np.sum(misidentified_BG, axis=0).reshape(misidentified_BG.shape[1], misidentified_BG.shape[2]), origin=\"lower\")\n",
    "ax.set_title(\"Background misidentified as Signal sum\")\n",
    "\n",
    "# colorbar with label\n",
    "cbar = fig.colorbar(im)\n",
    "cbar.ax.set_ylabel('Transverse Energy')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# start figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# plot the image\n",
    "im = ax.imshow(np.sum(misidentified_S, axis=0).reshape(misidentified_S.shape[1], misidentified_S.shape[2]), origin=\"lower\")\n",
    "ax.set_title(\"Signal misidentified as Background sum\")\n",
    "\n",
    "# colorbar with label\n",
    "cbar = fig.colorbar(im)\n",
    "cbar.ax.set_ylabel('Transverse Energy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is noticeable that this time, sum of backgrounds is more spreaded, while the signals sum is more localized. It appears as if the signals and jets switched characteristics. Just by looking at those sums of images, one can notice that sum of backgrounds misidentified as signals resembles sum of signals more than of backgrounds, and sum of signals misidentified as backgrounds, resembles sum of backgrounds. Since sums are just an average image multipled by number of images, it can be concluded that on average, images of signals that network mistakes as background, are similar to background and images of background that network mistakes for signals, are similar to signals. This hints that network's accuracy is limited by the similarity in the data, rather than by the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further analysis is done, by quantifying similarity using the Structural Similarity Index Measure (SSIM), which is used for classification of similarity of images based on intensity of their pixels and structures included in them. The SSIM score ranges from -1 to 1, with -1 indicating negative correlation, 0 - no similarity and 1 - perfect similarity between two images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# to focus on the structure, images are normalized by dividing every pixel by maximum value of a pixel in given image\n",
    "print(\"Similarity (SSIM score) between signal misidentified as background and signal is: \", \n",
    "      ssim(np.sum(misidentified_S, axis=0).reshape(40,40)/np.max(np.sum(misidentified_S, axis=0)),\n",
    "     np.sum(X_S, axis=0)/np.max(np.sum(X_S, axis=0))))\n",
    "\n",
    "print(\"Similarity (SSIM score) between signal misidentified as background and background is: \", \n",
    "      ssim(np.sum(misidentified_S, axis=0).reshape(40,40)/np.max(np.sum(misidentified_S, axis=0)),\n",
    "     np.sum(X_BG, axis=0)/np.max(np.sum(X_BG, axis=0))))\n",
    "\n",
    "\n",
    "print(\"Similarity (SSIM score) between background misidentified as signal and background is: \", \n",
    "      ssim(np.sum(misidentified_BG, axis=0).reshape(40,40)/np.max(np.sum(misidentified_BG, axis=0)),\n",
    "     np.sum(X_BG, axis=0)/np.max(np.sum(X_BG, axis=0))) )\n",
    "\n",
    "\n",
    "print(\"Similarity (SSIM score) between background misidentified as signal and signal is: \", \n",
    "      ssim(np.sum(misidentified_BG, axis=0).reshape(40,40)/np.max(np.sum(misidentified_BG, axis=0)),\n",
    "     np.sum(X_S, axis=0)/np.max(np.sum(X_S, axis=0))) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSIM indicates that signal misidentified as background is more similar to background than to signal. The background misidentified as signal is however slightly more similar to background than to signal, however the difference is very small. SSIM is of course, not perfect and that is why we have to rely on machine learning for this image classification. SSIM has very little parameters compared to complex neural network model built here, it gives us however some context, and partially agrees with observations that can be done by eye regarding similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the model can be considered good, as its accuracy is mostly limited by similarity in images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can take a look at the confidence levels predicted by the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_predicts = [] # sum of predictions\n",
    "confidence_that_is_S = [] # confidence that given image is a signal\n",
    "confidence_that_is_BG = [] # confidence that given image is a background\n",
    "\n",
    "# loop over test images\n",
    "for jet_image in X_test:\n",
    "\n",
    "    # Reshape the input image to match the expected shape of your model's input layer\n",
    "    input_image = jet_image.reshape( 1,40,40,1)\n",
    "\n",
    "    # Use the model to make a prediction for the input image\n",
    "    prediction = model.predict(input_image)\n",
    "\n",
    "\n",
    "    # Print the predicted class\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    #print(\"Predicted class:\", predicted_class)\n",
    "    \n",
    "    # update confidence lists with confidence values given by prediction\n",
    "    confidence_that_is_S.append(prediction[0][1])\n",
    "    confidence_that_is_BG.append(prediction[0][0])\n",
    "    \n",
    "    sum_predicts.append(prediction[0][0] + prediction[0][1]) # update list of sums of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting confidence of Signal classification as a histogram\n",
    "plt.figure()\n",
    "plt.hist(confidence_that_is_S,  bins=100)\n",
    "plt.title(\"Network confidence that given image is signal, histogram\")\n",
    "\n",
    "plt.xlabel('Confidence level predicted')\n",
    "\n",
    "plt.savefig('Histogram_network_confidence_that_signal.png', dpi=300)\n",
    "plt.ylabel('Counts')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting confidence of Background classification as a histogram\n",
    "plt.figure()\n",
    "plt.hist(confidence_that_is_BG,  bins=100)\n",
    "plt.title(\"Network confidence that given image is background histogram\")\n",
    "\n",
    "plt.xlabel('Confidence level predicted')\n",
    "plt.ylabel('Counts')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the two histograms are reversed, since the softmax function gives probabilities which sum up to 1.0 for all classes. So if network has confidence a that given image is background, its confidence that it is signal is 1-a. \n",
    "As expected, the most often occuring values are close to 1 and 0, as those are high confidence levels for either background or signal, indicating that in most cases network is confident in its prediction. There are however, some cases in between, close to 0.5 which suggests that those images were more difficult to classify for the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can take a look at particular identification probabilities. For example when images are really signal, how confident network is that it is signal. Those are then plotted as histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_prediction_when_S = [] # what is confidence that it is S when it really is S\n",
    "BG_prediction_when_BG = []  # what is confidence that it is BG when it really is BG\n",
    " \n",
    "# loop over test images\n",
    "index = 0\n",
    "while index < X_test.shape[0]:\n",
    "    input_image = X_test[index]\n",
    "    \n",
    "    # Reshape the input image to match the expected shape of your model's input layer\n",
    "    input_image = input_image.reshape( 1,40,40,1)\n",
    "    \n",
    "    # model's prediction\n",
    "    prediction = model.predict(input_image)\n",
    "    \n",
    "    # labels in y_test are [0,1] for signal and [1,0] for image\n",
    "    if y_test[index][1] > y_test[index][0]: # this is 1\n",
    "        S_prediction_when_S.append(prediction[0][1]) # update confidence list\n",
    "        \n",
    "    else: # this is 0\n",
    "        BG_prediction_when_BG.append(prediction[0][0]) # update confidence list\n",
    "    \n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.hist(S_prediction_when_S,  bins=100)\n",
    "\n",
    "plt.title(\"Network confidence that given signal is a signal histogram\")\n",
    "plt.xlabel('Confidence level predicted')\n",
    "plt.ylabel('Counts')\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.hist(BG_prediction_when_BG,  bins=100)\n",
    "\n",
    "plt.title(\"Network confidence that given background is a background histogram\")\n",
    "plt.xlabel('Confidence level predicted')\n",
    "plt.ylabel('Counts')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, in both of these histograms, the most confidence values are high, indicating that network is confidently making good predictions. In signal identification, there is a lot more low values than in background, with a small peak close to 0. This indicates, that there are some signal images which network finds similar to background, and there are much less background images which network finds similar to signal. This agrees with results from SSIM analysis, which showed that average misidentified signal is more similar to background than to signal, but that average misidentified background is similar to both background and signal.\n",
    "From those histograms, it can be concluded that the network is good at rejecting background (very little low confidence values for background), but it is slightly worse at identifying signals (some low confidence values indicating that some signals are misidentified as background. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As further investigation, we can plot the Receiver Operating Characteristic (ROC) curve. ROC can be used to investigate binary classifier, it is a relation of the true positive rate (TPR) to false positive rate (FPR). Those rates are defined as:\n",
    "\n",
    "$$ TPR = \\frac{True Positives Number}{(True Positives Number + False Negatives Number)}$$\n",
    "\n",
    "$$ FPR = \\frac{False Positives Number}{(False Positives Number + True Negatives Number)}$$\n",
    "\n",
    "A good classifier would have high TPR with simultaneousely low FPR. Random clasifier would have a ROC curve following TPR = FPR line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change labels format\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# generate predictions\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# compute the FPR, TPR, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test_labels, y_pred_prob[:,1])\n",
    "\n",
    "# compute the AUC\n",
    "roc_auc = roc_auc_score(y_test_labels, y_pred_prob[:,1])\n",
    "\n",
    "# plot the ROC curve using the FPR and TPR values\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label = 'random classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for CNN model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig('ROC_Curve.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve is above random classifier line as expected. Area under the curve (AUC) is 0.87, which indicates a relatively good classifier, a perfect classifier would have an AUC of 1.0, and random classifier would have an AUC of 0.5. \n",
    "The ROC curve, allows for choosing a confidence threshold for classification of images depending on what is needed. For example, if in some cases minimization of false positives must be prioritized, then threshold which grants low FPR should be chosen. On the other hand, in some cases we might want to minimize number of false negatives. In that situation, threshold should be chosen in such a way, as to result in high TPR. In our case, so far network has been using 0.5 as threshold, meaning that class with higher probability of the two is chosen. This can be artificially changed if needed, for example threshold could be lowered for signal classification to 0.4, which would mean that images which had signal concifence level predicted as between 0.5 and 0.4, would now be classified as signals instead of background. Whether the threshold should be unchanged, lowered or increased, depends on the specific situation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misidentified_BG_at_thresholds = []\n",
    "misidentified_S_at_thresholds = []\n",
    "accuracy_at_thresholds = []\n",
    "    \n",
    "for threshold in [-0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3]:\n",
    "    \n",
    "\n",
    "    index = 0 # index for the loop\n",
    "    misidentified_BG = [] # background misidentified as signal list\n",
    "    misidentified_S = [] # signal misidentified as background\n",
    "\n",
    "    S_threshold_increase = threshold # this will be used for changing threshold for classification\n",
    "\n",
    "    # loop over all test images\n",
    "    while index < X_test.shape[0]:\n",
    "        input_image = X_test[index]\n",
    "\n",
    "        input_image = input_image.reshape( 1,40,40,1) # reshape for the prediction\n",
    "\n",
    "        prediction_1 = model.predict(input_image) # model predict\n",
    "\n",
    "\n",
    "        prediction = np.array([[prediction_1[0][0] - S_threshold_increase\n",
    "                                , prediction_1[0][1] + S_threshold_increase]])\n",
    "\n",
    "\n",
    "        predicted_class = np.argmax(prediction)\n",
    "\n",
    "\n",
    "        if prediction[0][0] > prediction[0][1]: # this is predicted as 0\n",
    "            if y_test[index][1] > y_test[index][0]:\n",
    "                print(\"wrong, this is 1 (signal)\")\n",
    "                # predicted as background but it is really signal\n",
    "                misidentified_S.append(X_test[index]) # update list\n",
    "\n",
    "\n",
    "        elif y_test[index][0] > y_test[index][1]: \n",
    "            print(\"wrong, this is 0 (background)\")\n",
    "            # predicted as signal, but it is really background\n",
    "            misidentified_BG.append(X_test[index]) # update list\n",
    "\n",
    "\n",
    "        index = index + 1 # index increment\n",
    "        \n",
    "        \n",
    "    # turn lists into arrays\n",
    "    misidentified_BG = np.array(misidentified_BG)\n",
    "    misidentified_S = np.array(misidentified_S)\n",
    "\n",
    "    print(\"There are \",misidentified_BG.shape[0], \"BG misidentified as S\")\n",
    "    print(\"There are\",misidentified_S.shape[0], \"S misidentified as BG\")\n",
    "    print(\"Total accuracy, on all test images is: \", 1 - (misidentified_BG.shape[0] + misidentified_S.shape[0])/X_test.shape[0])\n",
    "    \n",
    "    # update lists\n",
    "    misidentified_BG_at_thresholds.append(misidentified_BG.shape[0])\n",
    "    misidentified_S_at_thresholds.append(misidentified_S.shape[0])\n",
    "    accuracy_at_thresholds.append(1 - (misidentified_BG.shape[0] + misidentified_S.shape[0])/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn lists into arrays\n",
    "misidentified_BG = np.array(misidentified_BG)\n",
    "misidentified_S = np.array(misidentified_S)\n",
    "\n",
    "print(\"There are \",misidentified_BG.shape[0], \"BG misidentified as S\")\n",
    "print(\"There are\",misidentified_S.shape[0], \"S misidentified as BG\")\n",
    "print(\"Total accuracy, on all test images is: \", 1 - (misidentified_BG.shape[0] + misidentified_S.shape[0])/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy vs threshold\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(0.5 - np.array([-0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3]), accuracy_at_thresholds, 'o-')\n",
    "\n",
    "plt.title('Accuracy of network at signal different thresholds')\n",
    "plt.xlabel('Threshold for Signal')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest obtained overall accuracy is for 0.4 threshold for signal (and therefore 0.6 for background). As expected accuracy is decreasing for very low and very high thresholds, hypothetically in limit of 0 or 1 thresholds, accuracy should be 0.5 as then only half of images would be classified. The threshold should overall be chosen depending on what is needed as mentioned before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain predicted probabilities for test data\n",
    "y_pred_proba = model.predict(X_test)\n",
    "\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "y_true = y_true.reshape(5000,1)\n",
    "\n",
    "# compute fpr, tpr, and thresholds using roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob[:,1])\n",
    "\n",
    "# compute rejection rate (1/fpr) and signal efficiency (tpr)\n",
    "rejection_rate = 1 / fpr\n",
    "signal_efficiency = tpr\n",
    "\n",
    "# plot the rejection/efficiency curve\n",
    "plt.semilogy(signal_efficiency, rejection_rate, label = 'Network')\n",
    "\n",
    "\n",
    "plt.semilogy(tpr, 1/tpr, \"--\", label = 'random classifier')\n",
    "\n",
    "plt.xlabel('Signal efficiency (tpr)')\n",
    "plt.ylabel('Background rejection (1/fpr)')\n",
    "plt.xlim(left=0.2)\n",
    "plt.ylim(1,100)\n",
    "plt.legend()\n",
    "plt.savefig('Background_rejection_efficiency.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8120\\2273215161.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# find rejection rate at 50% signal efficiency\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0midx_50\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal_efficiency\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrejection_rate_50\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrejection_rate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# find rejection rate at 80% signal efficiency\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# find rejection rate at 50% signal efficiency\n",
    "idx_50 = np.where(signal_efficiency >= 0.5)[0][0]\n",
    "rejection_rate_50 = rejection_rate[idx_50]\n",
    "\n",
    "# find rejection rate at 80% signal efficiency\n",
    "idx_80 = np.where(signal_efficiency >= 0.8)[0][0]\n",
    "rejection_rate_80 = rejection_rate[idx_80]\n",
    "\n",
    "# print results\n",
    "print(\"Rejection rate at 50% signal efficiency: {:.2f}\".format(rejection_rate_50))\n",
    "print(\"Rejection rate at 80% signal efficiency: {:.2f}\".format(rejection_rate_80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
